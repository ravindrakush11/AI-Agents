{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "hf-agent_orchestrate-a-multi-agent-system",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9956b3817324461bd8baf0c228b8e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_213214e087cd403481ff66158c00f7af"
          }
        },
        "1f11c3ac7dd14f4393517c12cce07425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4441ae1dc114874a3b17c2ee71ebf88",
            "placeholder": "​",
            "style": "IPY_MODEL_3ebc370265df408fa3afa793c2f24d7c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ecbf94195a0647929ffbb9847df8594d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_836a96104f3d466989bf045f0924c6be",
            "placeholder": "​",
            "style": "IPY_MODEL_c4fe83493b4844d89af7f9016e41cd62",
            "value": ""
          }
        },
        "41e7c7d82fa54b389ed8eb1cd2449e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_da17e729876a41ea917308e62ecc36eb",
            "style": "IPY_MODEL_712d0a184d6d41c2917d761a146349d5",
            "value": true
          }
        },
        "305ac3fbe41142309d8f14305e2ddd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_70d9e151f4414a61b102a0d1817bd5ea",
            "style": "IPY_MODEL_84f9478f7ebf4fe49e9d827b7d6ca938",
            "tooltip": ""
          }
        },
        "7f155b12d75f4447b1862f8f07535d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f941808ae5f4492e89363028f175f472",
            "placeholder": "​",
            "style": "IPY_MODEL_89d6f908e95244c9aa42458aeb37ede3",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "213214e087cd403481ff66158c00f7af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c4441ae1dc114874a3b17c2ee71ebf88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ebc370265df408fa3afa793c2f24d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "836a96104f3d466989bf045f0924c6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fe83493b4844d89af7f9016e41cd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da17e729876a41ea917308e62ecc36eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "712d0a184d6d41c2917d761a146349d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70d9e151f4414a61b102a0d1817bd5ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f9478f7ebf4fe49e9d827b7d6ca938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f941808ae5f4492e89363028f175f472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d6f908e95244c9aa42458aeb37ede3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0584c0f6087420899a82852dd54ee30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5456811d915b4a6aac90308d55e1ab4a",
            "placeholder": "​",
            "style": "IPY_MODEL_07ab88f31f59442288db73337ceab6ca",
            "value": "Connecting..."
          }
        },
        "5456811d915b4a6aac90308d55e1ab4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ab88f31f59442288db73337ceab6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrakush11/AI-Agents/blob/main/hf_agent_orchestrate_a_multi_agent_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Orchestrate a multi-agent system:--** a multi-agent web browser: an agentic system with several agents collaborating to solve problems using the web!"
      ],
      "metadata": {
        "id": "udEZ79lucS8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install smolagents[toolkit] --upgrade -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiHmdfKOcMfW",
        "outputId": "175edba0-e9db-4388-dcb5-0fb73e853a7e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:09.720562Z",
          "iopub.execute_input": "2025-05-17T04:42:09.720889Z",
          "iopub.status.idle": "2025-05-17T04:42:17.770011Z",
          "shell.execute_reply.started": "2025-05-17T04:42:09.720862Z",
          "shell.execute_reply": "2025-05-17T04:42:17.768771Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.2/484.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c9956b3817324461bd8baf0c228b8e07",
            "1f11c3ac7dd14f4393517c12cce07425",
            "ecbf94195a0647929ffbb9847df8594d",
            "41e7c7d82fa54b389ed8eb1cd2449e5e",
            "305ac3fbe41142309d8f14305e2ddd5c",
            "7f155b12d75f4447b1862f8f07535d30",
            "213214e087cd403481ff66158c00f7af",
            "c4441ae1dc114874a3b17c2ee71ebf88",
            "3ebc370265df408fa3afa793c2f24d7c",
            "836a96104f3d466989bf045f0924c6be",
            "c4fe83493b4844d89af7f9016e41cd62",
            "da17e729876a41ea917308e62ecc36eb",
            "712d0a184d6d41c2917d761a146349d5",
            "70d9e151f4414a61b102a0d1817bd5ea",
            "84f9478f7ebf4fe49e9d827b7d6ca938",
            "f941808ae5f4492e89363028f175f472",
            "89d6f908e95244c9aa42458aeb37ede3",
            "b0584c0f6087420899a82852dd54ee30",
            "5456811d915b4a6aac90308d55e1ab4a",
            "07ab88f31f59442288db73337ceab6ca",
            "4155ca44e9b244bea28a2564d419d672"
          ]
        },
        "id": "UVqpnMs-c3oN",
        "outputId": "326f3bb4-4eac-444d-af6f-833d34df7a4c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:17.771328Z",
          "iopub.execute_input": "2025-05-17T04:42:17.771584Z",
          "iopub.status.idle": "2025-05-17T04:42:18.228747Z",
          "shell.execute_reply.started": "2025-05-17T04:42:17.77156Z",
          "shell.execute_reply": "2025-05-17T04:42:18.227449Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4155ca44e9b244bea28a2564d419d672"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"Qwen/Qwen2.5-Coder-32B-Instruct\""
      ],
      "metadata": {
        "id": "rvUNufe9c_d8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:18.231085Z",
          "iopub.execute_input": "2025-05-17T04:42:18.231428Z",
          "iopub.status.idle": "2025-05-17T04:42:18.235988Z",
          "shell.execute_reply.started": "2025-05-17T04:42:18.2314Z",
          "shell.execute_reply": "2025-05-17T04:42:18.235082Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Web search tool"
      ],
      "metadata": {
        "id": "PaKJEdSfdN7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from markdownify import markdownify\n",
        "from requests.exceptions import RequestException\n",
        "from smolagents import tool\n",
        "\n",
        "@tool\n",
        "def visit_webpage(url: str) -> str:\n",
        "  \"\"\"Visits a webpage at the given URL and returns its content as markdown string.\n",
        "\n",
        "  Args:\n",
        "      url: The URL of the webpage to visit.\n",
        "\n",
        "  Returns:\n",
        "      The content of the webpage converted to Markdown, or an error message if the request fails.\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    markdown_content = markdownify(response.text).strip()\n",
        "\n",
        "    markdown_content = re.sub(r\"\\n{3,}\", \"\\n\\n\", markdown_content)\n",
        "\n",
        "    return markdown_content\n",
        "\n",
        "  except RequestException as e:\n",
        "    return f\"Error fetching the webpage: {str(e)}\"\n",
        "  except Exception as e:\n",
        "    return f\"An unexpected error occurred: {str(e)}\""
      ],
      "metadata": {
        "id": "AJCOhYPddQpZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:18.236746Z",
          "iopub.execute_input": "2025-05-17T04:42:18.236994Z",
          "iopub.status.idle": "2025-05-17T04:42:19.179925Z",
          "shell.execute_reply.started": "2025-05-17T04:42:18.236966Z",
          "shell.execute_reply": "2025-05-17T04:42:19.179102Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(visit_webpage(\"https://en.wikipedia.org/wiki/Hugging_Face\")[500:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4I_oWpeevFH",
        "outputId": "be171fbc-cb6c-4cbb-e935-543055b62b09",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:19.180844Z",
          "iopub.execute_input": "2025-05-17T04:42:19.181303Z",
          "iopub.status.idle": "2025-05-17T04:42:19.512344Z",
          "shell.execute_reply.started": "2025-05-17T04:42:19.18128Z",
          "shell.execute_reply": "2025-05-17T04:42:19.511307Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "ct us](//en.wikipedia.org/wiki/Wikipedia:Contact_us \"How to contact Wikipedia\")\n\nContribute\n\n* [Help](/wiki/Help:Contents \"Guidance on how to use and edit Wikipedia\")\n* [Learn to edit](/wiki/Help:Introduction \"Learn how to edit Wikipedia\")\n* [Community portal](/wiki/Wikipedia:Community_portal \"The hub for editors\")\n* [Recent changes](/wiki/Special:RecentChanges \"A list of recent changes to Wikipedia [r]\")\n* [Upload file](/wiki/Wikipedia:File_upload_wizard \"Add images or other media for use on Wikipedia\")\n* [Special pages](/wiki/Special:SpecialPages)\n\n[![](/static/images/icons/wikipedia.png)\n\n![Wikipedia](/static/images/mobile/copyright/wikipedia-wordmark-en.svg)\n![The Free Encyclopedia](/static/images/mobile/copyright/wikipedia-tagline-en.svg)](/wiki/Main_Page)\n\n[Search](/wiki/Special:Search \"Search Wikipedia [f]\")\n\nSearch\n\nAppearance\n\n* [Donate](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en)\n* [Create account](/w/index.php?title=Special:CreateAccount&returnto=Hugging+Face \"You are encouraged to create an account and log in; however, it is not mandatory\")\n* [Log in](/w/index.php?title=Special:UserLogin&returnto=Hugging+Face \"You're encouraged to log in; however, it's not mandatory. [o]\")\n\nPersonal tools\n\n* [Donate](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en)\n* [Create account](/w/index.php?title=Special:CreateAccount&returnto=Hugging+Face \"You are encouraged to create an account and log in; however, it is not mandatory\")\n* [Log in](/w/index.php?title=Special:UserLogin&returnto=Hugging+Face \"You're encouraged to log in; however, it's not mandatory. [o]\")\n\nPages for logged out editors [learn more](/wiki/Help:Introduction)\n\n* [Contributions](/wiki/Special:MyContributions \"A list of edits made from this IP address [y]\")\n* [Talk](/wiki/Special:MyTalk \"Discussion about edits from this IP address [n]\")\n\nContents\n--------\n\nmove to sidebar\nhide\n\n* [(Top)](#)\n* [1\n  History](#History)\n* [2\n  Services and technologies](#Services_and_technologies)\n\n  Toggle Services and technologies subsection\n  + [2.1\n    Transformers Library](#Transformers_Library)\n  + [2.2\n    Hugging Face Hub](#Hugging_Face_Hub)\n  + [2.3\n    Other libraries](#Other_libraries)\n  + [2.4\n    Safetensors](#Safetensors)\n* [3\n  See also](#See_also)\n* [4\n  References](#References)\n* [5\n  External links](#External_links)\n\nToggle the table of contents\n\nHugging Face\n============\n\n22 languages\n\n* [العربية](https://ar.wikipedia.org/wiki/%D9%87%D8%AC%D9%8A%D9%86%D8%AC_%D9%81%D9%8A%D8%B3 \"هجينج فيس – Arabic\")\n* [বাংলা](https://bn.wikipedia.org/wiki/%E0%A6%B9%E0%A6%BE%E0%A6%97%E0%A6%BF%E0%A6%82_%E0%A6%AB%E0%A7%87%E0%A6%B8 \"হাগিং ফেস – Bangla\")\n* [Català](https://ca.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Catalan\")\n* [Deutsch](https://de.wikipedia.org/wiki/Hugging_Face \"Hugging Face – German\")\n* [Español](https://es.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Spanish\")\n* [Euskara](https://eu.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Basque\")\n* [فارسی](https://fa.wikipedia.org/wiki/%D9%87%D8%A7%DA%AF%DB%8C%D9%86%DA%AF_%D9%81%DB%8C%D8%B3 \"هاگینگ فیس – Persian\")\n* [Français](https://fr.wikipedia.org/wiki/Hugging_Face \"Hugging Face – French\")\n* [한국어](https://ko.wikipedia.org/wiki/%ED%97%88%EA%B9%85_%ED%8E%98%EC%9D%B4%EC%8A%A4 \"허깅 페이스 – Korean\")\n* [Bahasa Indonesia](https://id.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Indonesian\")\n* [עברית](https://he.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Hebrew\")\n* [Nederlands](https://nl.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Dutch\")\n* [日本語](https://ja.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Japanese\")\n* [Polski](https://pl.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Polish\")\n* [Português](https://pt.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Portuguese\")\n* [Runa Simi](https://qu.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Quechua\")\n* [Русский](https://ru.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Russian\")\n* [Suomi](https://fi.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Finnish\")\n* [Türkçe](https://tr.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Turkish\")\n* [Українська](https://uk.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Ukrainian\")\n* [粵語](https://zh-yue.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Cantonese\")\n* [中文](https://zh.wikipedia.org/wiki/Hugging_Face \"Hugging Face – Chinese\")\n\n[Edit links](https://www.wikidata.org/wiki/Special:EntityPage/Q108943604#sitelinks-wikipedia \"Edit interlanguage links\")\n\n* [Article](/wiki/Hugging_Face \"View the content page [c]\")\n* [Talk](/wiki/Talk:Hugging_Face \"Discuss improvements to the content page [t]\")\n\nEnglish\n\n* [Read](/wiki/Hugging_Face)\n* [Edit](/w/index.php?title=Hugging_Face&action=edit \"Edit this page [e]\")\n* [View history](/w/index.php?title=Hugging_Face&action=history \"Past revisions of this page [h]\")\n\nTools\n\nTools\n\nmove to sidebar\nhide\n\nActions\n\n* [Read](/wiki/Hugging_Face)\n* [Edit](/w/index.php?title=Hugging_Face&action=edit \"Edit this page [e]\")\n* [View history](/w/index.php?title=Hugging_Face&action=history)\n\nGeneral\n\n* [What links here](/wiki/Special:WhatLinksHere/Hugging_Face \"List of all English Wikipedia pages containing links to this page [j]\")\n* [Related changes](/wiki/Special:RecentChangesLinked/Hugging_Face \"Recent changes in pages linked from this page [k]\")\n* [Upload file](//en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard \"Upload files [u]\")\n* [Permanent link](/w/index.php?title=Hugging_Face&oldid=1288693889 \"Permanent link to this revision of this page\")\n* [Page information](/w/index.php?title=Hugging_Face&action=info \"More information about this page\")\n* [Cite this page](/w/index.php?title=Special:CiteThisPage&page=Hugging_Face&id=1288693889&wpFormIdentifier=titleform \"Information on how to cite this page\")\n* [Get shortened URL](/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHugging_Face)\n* [Download QR code](/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHugging_Face)\n\nPrint/export\n\n* [Download as PDF](/w/index.php?title=Special:DownloadAsPdf&page=Hugging_Face&action=show-download-screen \"Download this page as a PDF file\")\n* [Printable version](/w/index.php?title=Hugging_Face&printable=yes \"Printable version of this page [p]\")\n\nIn other projects\n\n* [Wikimedia Commons](https://commons.wikimedia.org/wiki/Category:Hugging_Face)\n* [Wikidata item](https://www.wikidata.org/wiki/Special:EntityPage/Q108943604 \"Structured data on this page hosted by Wikidata [g]\")\n\nAppearance\n\nmove to sidebar\nhide\n\nFrom Wikipedia, the free encyclopedia\n\nFrench-American software company\n\nThis article is about the company. For the emoji, see [Emoji](/wiki/Emoji \"Emoji\").\n\n|  |  |\n| --- | --- |\n|  | This article **relies excessively on [references](/wiki/Wikipedia:Verifiability \"Wikipedia:Verifiability\") to [primary sources](/wiki/Wikipedia:No_original_research#Primary,_secondary_and_tertiary_sources \"Wikipedia:No original research\")**. Please improve this article by adding [secondary or tertiary sources](/wiki/Wikipedia:No_original_research#Primary,_secondary_and_tertiary_sources \"Wikipedia:No original research\").  *Find sources:* [\"Hugging Face\"](https://www.google.com/search?as_eq=wikipedia&q=%22Hugging+Face%22) – [news](https://www.google.com/search?tbm=nws&q=%22Hugging+Face%22+-wikipedia&tbs=ar:1) **·** [newspapers](https://www.google.com/search?&q=%22Hugging+Face%22&tbs=bkt:s&tbm=bks) **·** [books](https://www.google.com/search?tbs=bks:1&q=%22Hugging+Face%22+-wikipedia) **·** [scholar](https://scholar.google.com/scholar?q=%22Hugging+Face%22) **·** [JSTOR](https://www.jstor.org/action/doBasicSearch?Query=%22Hugging+Face%22&acc=on&wc=on) *(February 2024)* *([Learn how and when to remove this message](/wiki/Help:Maintenance_template_removal \"Help:Maintenance template removal\"))* |\n\nHugging Face, Inc.\n\n|  |  |\n| --- | --- |\n|  | |\n| Company type | [Private](/wiki/Privately_held_company \"Privately held company\") |\n| Industry | [Artificial intelligence](/wiki/Artificial_intelligence \"Artificial intelligence\") [machine learning](/wiki/Machine_learning \"Machine learning\") [software development](/wiki/Software_development \"Software development\") |\n| Founded | 2016; 9 years ago (2016) |\n| Headquarters | [Manhattan](/wiki/Manhattan \"Manhattan\"), [New York City](/wiki/New_York_City \"New York City\") |\n| Area served | Worldwide |\n| Key people | * Clément Delangue (CEO) * Julien Chaumond (CTO) * Thomas Wolf (CSO) |\n| Products | Models, datasets spaces |\n| Revenue | Increase US$15 million (2022) |\n| Number of employees | 170 (2023) |\n| Website | [huggingface.co](https://huggingface.co/) |\n\n**Hugging Face, Inc.** is a French-American company based in [New York City](/wiki/List_of_tech_companies_in_the_New_York_metropolitan_area \"List of tech companies in the New York metropolitan area\") that develops [computation](/wiki/Computation \"Computation\") tools for building applications using [machine learning](/wiki/Machine_learning \"Machine learning\"). It is most notable for its [transformers](/wiki/Transformer_(machine_learning_model) \"Transformer (machine learning model)\") [library](/wiki/Software_libraries \"Software libraries\") built for [natural language processing](/wiki/Natural_language_processing \"Natural language processing\") applications and its platform that allows users to share machine learning models and [datasets](/wiki/Dataset_(machine_learning) \"Dataset (machine learning)\") and showcase their work.\n\nHistory\n-------\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=1 \"Edit section: History\")]\n\nThe company was founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf in [New York City](/wiki/New_York_City \"New York City\"), originally as a company that developed a [chatbot](/wiki/Chatbot \"Chatbot\") app targeted at teenagers.[[1]](#cite_note-:0-1) The company was named after the U+1F917 🤗 HUGGING FACE [emoji](/wiki/Emoji \"Emoji\").[[1]](#cite_note-:0-1) After [open sourcing](/wiki/Open-source_software \"Open-source software\") the model behind the chatbot, the company [pivoted](/wiki/Lean_startup \"Lean startup\") to focus on being a platform for machine learning.\n\nIn March 2021, Hugging Face raised US$40 million in a [Series B](/wiki/Series_B \"Series B\") funding round.[[2]](#cite_note-2)\n\nOn April 28, 2021, the company launched the BigScience Research Workshop in collaboration with several other research groups to release an open [large language model](/wiki/Large_language_model \"Large language model\").[[3]](#cite_note-3) In 2022, the workshop concluded with the announcement of [BLOOM](/wiki/BLOOM_(language_model) \"BLOOM (language model)\"), a multilingual large language model with 176 billion parameters.[[4]](#cite_note-4)[[5]](#cite_note-5)\n\nIn December 2022, the company acquired Gradio, an open source library built for developing machine learning applications in Python.[[6]](#cite_note-6)\n\nOn May 5, 2022, the company announced its [Series C](/wiki/Series_C \"Series C\") funding round led by [Coatue](/wiki/Coatue_Management \"Coatue Management\") and [Sequoia](/wiki/Sequoia_fund \"Sequoia fund\").[[7]](#cite_note-7) The company received a $2 billion valuation.\n\nOn August 3, 2022, the company announced the Private Hub, an enterprise version of its public Hugging Face Hub that supports [SaaS](/wiki/Software_as_a_service \"Software as a service\") or [on-premises](/wiki/On-premises_software \"On-premises software\") deployment.[[8]](#cite_note-8)\n\nIn February 2023, the company announced partnership with [Amazon Web Services](/wiki/Amazon_Web_Services \"Amazon Web Services\") (AWS) which would allow Hugging Face's products available to AWS customers to use them as the building blocks for their custom applications. The company also said the next generation of BLOOM will be run on Trainium, a proprietary [machine learning chip](/wiki/Machine_learning_hardware \"Machine learning hardware\") created by AWS.[[9]](#cite_note-9)[[10]](#cite_note-10)[[11]](#cite_note-11)\n\nIn August 2023, the company announced that it raised $235 million in a [Series D](/wiki/Series_D \"Series D\") funding, at a $4.5 billion valuation. The funding was led by [Salesforce](/wiki/Salesforce \"Salesforce\"), and notable participation came from [Google](/wiki/Google \"Google\"), [Amazon](/wiki/Amazon_(company) \"Amazon (company)\"), [Nvidia](/wiki/Nvidia \"Nvidia\"), [AMD](/wiki/AMD \"AMD\"), [Intel](/wiki/Intel \"Intel\"), [IBM](/wiki/IBM \"IBM\"), and [Qualcomm](/wiki/Qualcomm \"Qualcomm\").[[12]](#cite_note-12)\n\nIn June 2024, the company announced, along with [Meta](/wiki/Meta_Platforms \"Meta Platforms\") and [Scaleway](/wiki/Scaleway \"Scaleway\"), their launch of a new AI accelerator program for European startups. This initiative aims to help startups integrate open foundation models into their products, accelerating the EU AI ecosystem. The program, based at STATION F in Paris, will run from September 2024 to February 2025. Selected startups will receive mentoring, access to AI models and tools, and Scaleway’s computing power.[[13]](#cite_note-13)\n\nOn September 23, 2024, to further the [International Decade of Indigenous Languages](/wiki/International_Decade_of_Indigenous_Languages \"International Decade of Indigenous Languages\"), Hugging Face teamed up with Meta and [UNESCO](/wiki/UNESCO \"UNESCO\") to launch a new online language translator [[14]](#cite_note-14) built on Meta's No Language Left Behind open-source AI model, enabling free text translation across 200 languages, including many low-resource languages.[[15]](#cite_note-15)\n\nOn April 2025, Hugging Face announced that they acquired a humanoid robotics startup, Pollen Robotics. Pollen Robotics is a France based Robotics Startup founded by Matthieu Lapeyre and Pierre Rouanet in 2016.[[16]](#cite_note-16)[[17]](#cite_note-17) In an X tweet, Clement Delangue - CEO of Hugging Face, share his vision to make Artificial Intelligence robotics Open Source.[[18]](#cite_note-18)\n\nServices and technologies\n-------------------------\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=2 \"Edit section: Services and technologies\")]\n\n### Transformers Library\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=3 \"Edit section: Transformers Library\")]\n\nThe Transformers library is a [Python](/wiki/Python_(programming_language) \"Python (programming language)\") package that contains open-source implementations of [transformer](/wiki/Transformer_(machine_learning_model) \"Transformer (machine learning model)\") models for text, image, and audio tasks. It is compatible with the [PyTorch](/wiki/PyTorch \"PyTorch\"), [TensorFlow](/wiki/TensorFlow \"TensorFlow\") and [JAX](/wiki/Google_JAX \"Google JAX\") [deep learning](/wiki/Deep_learning \"Deep learning\") libraries and includes implementations of notable models like [BERT](/wiki/BERT_(language_model) \"BERT (language model)\") and [GPT-2](/wiki/GPT-2 \"GPT-2\").[[19]](#cite_note-19) The library was originally called \"pytorch-pretrained-bert\"[[20]](#cite_note-20) which was then renamed to \"pytorch-transformers\" and finally \"transformers.\"\n\nA [javascript](/wiki/JavaScript \"JavaScript\") version (transformers.js[[21]](#cite_note-21)) has also been developed, allowing models to run directly in the browser through [ONNX](/wiki/Open_Neural_Network_Exchange \"Open Neural Network Exchange\") runtime.\n\n### Hugging Face Hub\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=4 \"Edit section: Hugging Face Hub\")]\n\nThe Hugging Face Hub is a platform (centralized [web service](/wiki/Web_service \"Web service\")) for hosting:[[22]](#cite_note-22)\n\n* [Git](/wiki/Git \"Git\")-based [code repositories](/wiki/Repository_(version_control) \"Repository (version control)\"), including discussions and pull requests for projects.\n* models, also with Git-based version control;\n* datasets, mainly in text, images, and audio;\n* web applications (\"spaces\" and \"widgets\"), intended for small-scale demos of machine learning applications.\n\nThere are numerous pre-trained models that support common tasks in different modalities, such as:\n\n* [Natural Language Processing](/wiki/Natural_language_processing \"Natural language processing\"): text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation.\n* [Computer Vision](/wiki/Computer_vision \"Computer vision\"): image classification, object detection, and segmentation.\n* Audio: automatic speech recognition and audio classification.\n\n### Other libraries\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=5 \"Edit section: Other libraries\")]\n\n[![](//upload.wikimedia.org/wikipedia/commons/thumb/2/29/Gradio_example.png/250px-Gradio_example.png)](/wiki/File:Gradio_example.png)\n\nGradio UI Example\n\nIn addition to Transformers and the Hugging Face Hub, the Hugging Face ecosystem contains libraries for other tasks, such as [dataset processing](/wiki/Data_processing \"Data processing\") (\"Datasets\"), model evaluation (\"Evaluate\"), and machine learning demos (\"Gradio\").[[23]](#cite_note-23)\n\n### Safetensors\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=6 \"Edit section: Safetensors\")]\n\nThe safetensors format was developed around 2021 to solve problems with the pickle format in python. It was designed for saving and loading tensors. Compared to pickle format, it allows lazy loading, and avoids security problems.[[24]](#cite_note-24) After a security audit, it became the default format in 2023.[[25]](#cite_note-25)\n\nThe file format:\n\n* size of the header: 8 bytes, an unsigned little-endian 64-bit integer.\n* header: JSON UTF-8 string, formatted as {\"TENSOR\\_NAME\": {“dtype”: “F16”, “shape”: [1, 16, 256], “data\\_offsets”: [BEGIN, END]}, \"NEXT\\_TENSOR\\_NAME\": {…}, …}.\n* file: a byte buffer containing the tensors.\n\nSee also\n--------\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=7 \"Edit section: See also\")]\n\n* [OpenAI](/wiki/OpenAI \"OpenAI\")\n* [Station F](/wiki/Station_F \"Station F\")\n* [Kaggle](/wiki/Kaggle \"Kaggle\")\n\nReferences\n----------\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=8 \"Edit section: References\")]\n\n1. ^ [***a***](#cite_ref-:0_1-0) [***b***](#cite_ref-:0_1-1) [\"Hugging Face wants to become your artificial BFF\"](https://techcrunch.com/2017/03/09/hugging-face-wants-to-become-your-artificial-bff/). *TechCrunch*. 9 March 2017. [Archived](https://web.archive.org/web/20220925012620/https://techcrunch.com/2017/03/09/hugging-face-wants-to-become-your-artificial-bff/) from the original on 2022-09-25. Retrieved 2023-09-17.\n2. **[^](#cite_ref-2)** [\"Hugging Face raises $40 million for its natural language processing library\"](https://techcrunch.com/2021/03/11/hugging-face-raises-40-million-for-its-natural-language-processing-library). 11 March 2021. [Archived](https://web.archive.org/web/20230728113102/https://techcrunch.com/2021/03/11/hugging-face-raises-40-million-for-its-natural-language-processing-library/) from the original on 28 July 2023. Retrieved 5 August 2022.\n3. **[^](#cite_ref-3)** [\"Inside BigScience, the quest to build a powerful open language model\"](https://venturebeat.com/2022/01/10/inside-bigscience-the-quest-to-build-a-powerful-open-language-model/). 10 January 2022. [Archived](https://web.archive.org/web/20220701073233/https://venturebeat.com/2022/01/10/inside-bigscience-the-quest-to-build-a-powerful-open-language-model/) from the original on 1 July 2022. Retrieved 5 August 2022.\n4. **[^](#cite_ref-4)** [\"BLOOM\"](https://bigscience.huggingface.co/blog/bloom). *bigscience.huggingface.co*. [Archived](https://web.archive.org/web/20221114122342/https://bigscience.huggingface.co/blog/bloom) from the original on 2022-11-14. Retrieved 2022-08-20.\n5. **[^](#cite_ref-5)** [\"Inside a radical new project to democratize AI\"](https://www.technologyreview.com/2022/07/12/1055817/inside-a-radical-new-project-to-democratize-ai/). *MIT Technology Review*. [Archived](https://web.archive.org/web/20221204184214/https://www.technologyreview.com/2022/07/12/1055817/inside-a-radical-new-project-to-democratize-ai/) from the original on 2022-12-04. Retrieved 2023-08-25.\n6. **[^](#cite_ref-6)** Nataraj, Poornima (2021-12-23). [\"Hugging Face Acquires Gradio, A Customizable UI Components Library For Python\"](https://analyticsindiamag.com/hugging-face-acquires-gradio-a-customizable-ui-components-library-for-python/). *Analytics India Magazine*. Retrieved 2024-01-26.\n7. **[^](#cite_ref-7)** Cai, Kenrick. [\"The $2 Billion Emoji: Hugging Face Wants To Be Launchpad For A Machine Learning Revolution\"](https://www.forbes.com/sites/kenrickcai/2022/05/09/the-2-billion-emoji-hugging-face-wants-to-be-launchpad-for-a-machine-learning-revolution/). *Forbes*. [Archived](https://web.archive.org/web/20221103121236/https://www.forbes.com/sites/kenrickcai/2022/05/09/the-2-billion-emoji-hugging-face-wants-to-be-launchpad-for-a-machine-learning-revolution/) from the original on 2022-11-03. Retrieved 2022-08-20.\n8. **[^](#cite_ref-8)** [\"Introducing the Private Hub: A New Way to Build With Machine Learning\"](https://huggingface.co/blog/introducing-private-hub). *huggingface.co*. [Archived](https://web.archive.org/web/20221114122333/https://huggingface.co/blog/introducing-private-hub) from the original on 2022-11-14. Retrieved 2022-08-20.\n9. **[^](#cite_ref-9)** Bass, Dina (2023-02-21). [\"Amazon's Cloud Unit Partners With Startup Hugging Face as AI Deals Heat Up\"](https://www.bloomberg.com/news/articles/2023-02-21/amazon-s-aws-joins-with-ai-startup-hugging-face-as-chatgpt-competition-heats-up). *[Bloomberg News](/wiki/Bloomberg_News \"Bloomberg News\")*. [Archived](https://web.archive.org/web/20230522030130/https://www.bloomberg.com/news/articles/2023-02-21/amazon-s-aws-joins-with-ai-startup-hugging-face-as-chatgpt-competition-heats-up) from the original on 2023-05-22. Retrieved 2023-02-22.\n10. **[^](#cite_ref-10)** Nellis, Stephen (2023-02-21). [\"Amazon Web Services pairs with Hugging Face to target AI developers\"](https://www.reuters.com/technology/amazon-web-services-pairs-with-hugging-face-target-ai-developers-2023-02-21/). *Reuters*. [Archived](https://web.archive.org/web/20230530091325/https://www.reuters.com/technology/amazon-web-services-pairs-with-hugging-face-target-ai-developers-2023-02-21/) from the original on 2023-05-30. Retrieved 2023-02-22.\n11. **[^](#cite_ref-11)** [\"AWS and Hugging Face collaborate to make generative AI more accessible and cost efficient | AWS Machine Learning Blog\"](https://aws.amazon.com/blogs/machine-learning/aws-and-hugging-face-collaborate-to-make-generative-ai-more-accessible-and-cost-efficient/). *aws.amazon.com*. 2023-02-21. [Archived](https://web.archive.org/web/20230825202343/https://aws.amazon.com/blogs/machine-learning/aws-and-hugging-face-collaborate-to-make-generative-ai-more-accessible-and-cost-efficient/) from the original on 2023-08-25. Retrieved 2023-08-25.\n12. **[^](#cite_ref-12)** Leswing, Kif (2023-08-24). [\"Google, Amazon, Nvidia and other tech giants invest in AI startup Hugging Face, sending its valuation to $4.5 billion\"](https://www.cnbc.com/2023/08/24/google-amazon-nvidia-amd-other-tech-giants-invest-in-hugging-face.html). *CNBC*. [Archived](https://web.archive.org/web/20230824141538/https://www.cnbc.com/2023/08/24/google-amazon-nvidia-amd-other-tech-giants-invest-in-hugging-face.html) from the original on 2023-08-24. Retrieved 2023-08-24.\n13. **[^](#cite_ref-13)** [\"META Collaboration Launches AI Accelerator for European Startups\"](https://finance.yahoo.com/news/meta-collaboration-launches-ai-accelerator-151500146.html). *Yahoo Finance*. 2024-06-25. Retrieved 2024-07-11.\n14. **[^](#cite_ref-14)** [\"Hugging Face Spaces Translator\"](https://huggingface.co/spaces/UNESCO/nllb.html). 2024-09-23.\n15. **[^](#cite_ref-15)** [\"UNESCO Translator Event\"](https://www.unesco.org/en/event/unesco-language-translator-powered-meta-and-hugging-face-launching-event?hub=68184.html). 2024-09-23.\n16. **[^](#cite_ref-16)** Wiggers, Kyle (2025-04-14). [\"Hugging Face buys a humanoid robotics startup\"](https://techcrunch.com/2025/04/14/hugging-face-buys-a-humanoid-robotics-startup/). *TechCrunch*. Retrieved 2025-04-15.\n17. **[^](#cite_ref-17)** Koetsier, John. [\"Open Source Humanoid Robots That You Can 3D Print Yourself: Hugging Face Buys Pollen Robotics\"](https://www.forbes.com/sites/johnkoetsier/2025/04/14/open-source-humanoid-robots-hugging-face-buys-pollen-robotics/). *Forbes*. Retrieved 2025-04-15.\n18. **[^](#cite_ref-18)** Knight, Will. [\"An Open Source Pioneer Wants to Unleash Open Source AI Robots\"](https://www.wired.com/story/hugging-face-acquires-open-source-robot-startup/). *Wired*. [ISSN](/wiki/ISSN_(identifier) \"ISSN (identifier)\") [1059-1028](https://search.worldcat.org/issn/1059-1028). Retrieved 2025-04-15.\n19. **[^](#cite_ref-19)** [\"🤗 Transformers\"](https://huggingface.co/docs/transformers/index). *huggingface.co*. [Archived](https://web.archive.org/web/20230927023923/https://huggingface.co/docs/transformers/index) from the original on 2023-09-27. Retrieved 2022-08-20.\n20. **[^](#cite_ref-20)** [\"First release\"](https://github.com/huggingface/transformers/releases/tag/v0.1.2). *GitHub*. Nov 17, 2018. [Archived](https://web.archive.org/web/20230430011038/https://github.com/huggingface/transformers/releases/tag/v0.1.2) from the original on 30 April 2023. Retrieved 28 March 2023.\n21. **[^](#cite_ref-21)** [\"xenova/transformers.js\"](https://github.com/xenova/transformers.js). *GitHub*.\n22. **[^](#cite_ref-22)** [\"Hugging Face Hub documentation\"](https://huggingface.co/docs/hub/index). *huggingface.co*. [Archived](https://web.archive.org/web/20230920185949/https://huggingface.co/docs/hub/index) from the original on 2023-09-20. Retrieved 2022-08-20.\n23. **[^](#cite_ref-23)** [\"Hugging Face - Documentation\"](https://huggingface.co/docs). *huggingface.co*. [Archived](https://web.archive.org/web/20230930074626/https://huggingface.co/docs) from the original on 2023-09-30. Retrieved 2023-02-18.\n24. **[^](#cite_ref-24)** [*huggingface/safetensors*](https://github.com/huggingface/safetensors#yet-another-format-), Hugging Face, 2024-09-21, retrieved 2024-09-22\n25. **[^](#cite_ref-25)** [\"🐶Safetensors audited as really safe and becoming the default\"](https://huggingface.co/blog/safetensors-security-audit). *huggingface.co*. Retrieved 2024-09-22.\n\nExternal links\n--------------\n\n[[edit](/w/index.php?title=Hugging_Face&action=edit&section=9 \"Edit section: External links\")]\n\n* [Official website](https://huggingface.co/) [![Edit this at Wikidata](//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png)](https://www.wikidata.org/wiki/Q108943604#P856 \"Edit this at Wikidata\")\n\n| * [v](/wiki/Template:Generative_AI \"Template:Generative AI\") * [t](/wiki/Template_talk:Generative_AI \"Template talk:Generative AI\") * [e](/wiki/Special:EditPage/Template:Generative_AI \"Special:EditPage/Template:Generative AI\")  [Generative AI](/wiki/Generative_artificial_intelligence \"Generative artificial intelligence\") | |\n| --- | --- |\n| Concepts | * [Autoencoder](/wiki/Autoencoder \"Autoencoder\") * [Deep learning](/wiki/Deep_learning \"Deep learning\") * [Generative adversarial network](/wiki/Generative_adversarial_network \"Generative adversarial network\") * [Generative pre-trained transformer](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\") * [Large language model](/wiki/Large_language_model \"Large language model\") * [Model Context Protocol](/wiki/Model_Context_Protocol \"Model Context Protocol\") * [Neural network](/wiki/Neural_network_(machine_learning) \"Neural network (machine learning)\") * [Prompt engineering](/wiki/Prompt_engineering \"Prompt engineering\") * [Retrieval-augmented generation](/wiki/Retrieval-augmented_generation \"Retrieval-augmented generation\") * [Reinforcement learning from human feedback](/wiki/Reinforcement_learning_from_human_feedback \"Reinforcement learning from human feedback\") * [Self-supervised learning](/wiki/Self-supervised_learning \"Self-supervised learning\") * [Transformer](/wiki/Transformer_(deep_learning_architecture) \"Transformer (deep learning architecture)\") * [Variational autoencoder](/wiki/Variational_autoencoder \"Variational autoencoder\") * [Vision transformer](/wiki/Vision_transformer \"Vision transformer\") * [Word embedding](/wiki/Word_embedding \"Word embedding\") |\n| Models | |  |  | | --- | --- | | Text | * [Claude](/wiki/Claude_(language_model) \"Claude (language model)\") * [DBRX](/wiki/DBRX \"DBRX\") * [DeepSeek](/wiki/DeepSeek_(chatbot) \"DeepSeek (chatbot)\") * [ERNIE](/wiki/Ernie_Bot \"Ernie Bot\") * [Gemini](/wiki/Gemini_(chatbot) \"Gemini (chatbot)\") * [GPT](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\")   + [1](/wiki/GPT-1 \"GPT-1\")   + [2](/wiki/GPT-2 \"GPT-2\")   + [3](/wiki/GPT-3 \"GPT-3\")   + [J](/wiki/GPT-J \"GPT-J\")   + [ChatGPT](/wiki/ChatGPT \"ChatGPT\")   + [4](/wiki/GPT-4 \"GPT-4\")   + [4o](/wiki/GPT-4o \"GPT-4o\")   + [o1](/wiki/OpenAI_o1 \"OpenAI o1\")   + [o3](/wiki/OpenAI_o3 \"OpenAI o3\")   + [4.5](/wiki/GPT-4.5 \"GPT-4.5\")   + [4.1](/wiki/GPT-4.1 \"GPT-4.1\")   + [o4](/wiki/OpenAI_o4 \"OpenAI o4\") * [Granite](/wiki/IBM_Granite \"IBM Granite\") * [Grok](/wiki/Grok_(chatbot) \"Grok (chatbot)\") * [Llama](/wiki/Llama_(language_model) \"Llama (language model)\") * [Manus](/wiki/Manus_(AI_agent) \"Manus (AI agent)\") * [Mistral Large](/wiki/Mistral_AI#Mistral_Large \"Mistral AI\") * [PanGu-Σ](/wiki/Huawei_PanGu \"Huawei PanGu\") * [Qwen](/wiki/Qwen \"Qwen\") | | [Image](/wiki/Text-to-image_model \"Text-to-image model\") | * [Aurora](/wiki/Aurora_(text-to-image_model) \"Aurora (text-to-image model)\") * [DALL-E](/wiki/DALL-E \"DALL-E\") * [Firefly](/wiki/Adobe_Firefly \"Adobe Firefly\") * [Flux](/wiki/Flux_(text-to-image_model) \"Flux (text-to-image model)\") * [GPT Image 1](/wiki/GPT-4o#GPT_Image_1 \"GPT-4o\") * [Ideogram](/wiki/Ideogram_(text-to-image_model) \"Ideogram (text-to-image model)\") * [Imagen](/wiki/Imagen_(text-to-image_model) \"Imagen (text-to-image model)\") * [Midjourney](/wiki/Midjourney \"Midjourney\") * [Stable Diffusion](/wiki/Stable_Diffusion \"Stable Diffusion\") | | Speech | * [15.ai](/wiki/15.ai \"15.ai\") * [WaveNet](/wiki/WaveNet \"WaveNet\") | | [Video](/wiki/Text-to-video_model \"Text-to-video model\") | * [Dream Machine](/wiki/Dream_Machine_(text-to-video_model) \"Dream Machine (text-to-video model)\") * [Gen-4](/wiki/Runway_(company)#Gen-4 \"Runway (company)\") * [Hailuo AI](/wiki/MiniMax_(company)#Hailuo_AI \"MiniMax (company)\") * [Kling](/wiki/Kling_(text-to-video_model) \"Kling (text-to-video model)\") * [Sora](/wiki/Sora_(text-to-video_model) \"Sora (text-to-video model)\") * [Veo](/wiki/Google_DeepMind#Video_generation \"Google DeepMind\") * [VideoPoet](/wiki/VideoPoet \"VideoPoet\") | | Music | * [Endel](/wiki/Endel_(app) \"Endel (app)\") * [Suno AI](/wiki/Suno_AI \"Suno AI\") * [Udio](/wiki/Udio \"Udio\") | |\n| [Companies](/wiki/List_of_artificial_intelligence_companies \"List of artificial intelligence companies\") | * [01.AI](/wiki/01.AI \"01.AI\") * [Alibaba](/wiki/Alibaba_Group \"Alibaba Group\") * [Anthropic](/wiki/Anthropic \"Anthropic\") * [Baichuan](/wiki/Baichuan \"Baichuan\") * [Baidu](/wiki/Baidu \"Baidu\") * [Cohere](/wiki/Cohere \"Cohere\") * [DeepSeek](/wiki/DeepSeek \"DeepSeek\") * [ElevenLabs](/wiki/ElevenLabs \"ElevenLabs\") * [Google DeepMind](/wiki/Google_DeepMind \"Google DeepMind\") * Hugging Face * [Kuaishou](/wiki/Kuaishou \"Kuaishou\") * [Meta AI](/wiki/Meta_AI \"Meta AI\") * [MiniMax](/wiki/MiniMax_(company) \"MiniMax (company)\") * [Mistral AI](/wiki/Mistral_AI \"Mistral AI\") * [Moonshot AI](/wiki/Moonshot_AI \"Moonshot AI\") * [OpenAI](/wiki/OpenAI \"OpenAI\") * [Runway](/wiki/Runway_(company) \"Runway (company)\") * [Stability AI](/wiki/Stability_AI \"Stability AI\") * [Synthesia](/wiki/Synthesia_(company) \"Synthesia (company)\") * [xAI](/wiki/XAI_(company) \"XAI (company)\") * [Zhipu AI](/wiki/Zhipu_AI \"Zhipu AI\") |\n| * **[Category](/wiki/Category:Generative_artificial_intelligence \"Category:Generative artificial intelligence\")** * **[Commons](https://commons.wikimedia.org/wiki/Category:Generative_artificial_intelligence \"commons:Category:Generative artificial intelligence\")** | |\n\n| * [v](/wiki/Template:Artificial_intelligence_navbox \"Template:Artificial intelligence navbox\") * [t](/wiki/Template_talk:Artificial_intelligence_navbox \"Template talk:Artificial intelligence navbox\") * [e](/wiki/Special:EditPage/Template:Artificial_intelligence_navbox \"Special:EditPage/Template:Artificial intelligence navbox\")  [Artificial intelligence](/wiki/Artificial_intelligence \"Artificial intelligence\") (AI) | |\n| --- | --- |\n| [History](/wiki/History_of_artificial_intelligence \"History of artificial intelligence\") ([timeline](/wiki/Timeline_of_artificial_intelligence \"Timeline of artificial intelligence\")) | |\n| Concepts | * [Parameter](/wiki/Parameter \"Parameter\")   + [Hyperparameter](/wiki/Hyperparameter_(machine_learning) \"Hyperparameter (machine learning)\") * [Loss functions](/wiki/Loss_functions_for_classification \"Loss functions for classification\") * [Regression](/wiki/Regression_analysis \"Regression analysis\")   + [Bias–variance tradeoff](/wiki/Bias%E2%80%93variance_tradeoff \"Bias–variance tradeoff\")   + [Double descent](/wiki/Double_descent \"Double descent\")   + [Overfitting](/wiki/Overfitting \"Overfitting\") * [Clustering](/wiki/Cluster_analysis \"Cluster analysis\") * [Gradient descent](/wiki/Gradient_descent \"Gradient descent\")   + [SGD](/wiki/Stochastic_gradient_descent \"Stochastic gradient descent\")   + [Quasi-Newton method](/wiki/Quasi-Newton_method \"Quasi-Newton method\")   + [Conjugate gradient method](/wiki/Conjugate_gradient_method \"Conjugate gradient method\") * [Backpropagation](/wiki/Backpropagation \"Backpropagation\") * [Attention](/wiki/Attention_(machine_learning) \"Attention (machine learning)\") * [Convolution](/wiki/Convolution \"Convolution\") * [Normalization](/wiki/Normalization_(machine_learning) \"Normalization (machine learning)\")   + [Batchnorm](/wiki/Batch_normalization \"Batch normalization\") * [Activation](/wiki/Activation_function \"Activation function\")   + [Softmax](/wiki/Softmax_function \"Softmax function\")   + [Sigmoid](/wiki/Sigmoid_function \"Sigmoid function\")   + [Rectifier](/wiki/Rectifier_(neural_networks) \"Rectifier (neural networks)\") * [Gating](/wiki/Gating_mechanism \"Gating mechanism\") * [Weight initialization](/wiki/Weight_initialization \"Weight initialization\") * [Regularization](/wiki/Regularization_(mathematics) \"Regularization (mathematics)\") * [Datasets](/wiki/Training,_validation,_and_test_data_sets \"Training, validation, and test data sets\")   + [Augmentation](/wiki/Data_augmentation \"Data augmentation\") * [Prompt engineering](/wiki/Prompt_engineering \"Prompt engineering\") * [Reinforcement learning](/wiki/Reinforcement_learning \"Reinforcement learning\")   + [Q-learning](/wiki/Q-learning \"Q-learning\")   + [SARSA](/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action \"State–action–reward–state–action\")   + [Imitation](/wiki/Imitation_learning \"Imitation learning\")   + [Policy gradient](/wiki/Policy_gradient_method \"Policy gradient method\") * [Diffusion](/wiki/Diffusion_process \"Diffusion process\") * [Latent diffusion model](/wiki/Latent_diffusion_model \"Latent diffusion model\") * [Autoregression](/wiki/Autoregressive_model \"Autoregressive model\") * [Adversary](/wiki/Adversarial_machine_learning \"Adversarial machine learning\") * [RAG](/wiki/Retrieval-augmented_generation \"Retrieval-augmented generation\") * [Uncanny valley](/wiki/Uncanny_valley \"Uncanny valley\") * [RLHF](/wiki/Reinforcement_learning_from_human_feedback \"Reinforcement learning from human feedback\") * [Self-supervised learning](/wiki/Self-supervised_learning \"Self-supervised learning\") * [Recursive self-improvement](/wiki/Recursive_self-improvement \"Recursive self-improvement\") * [Word embedding](/wiki/Word_embedding \"Word embedding\") * [Hallucination](/wiki/Hallucination_(artificial_intelligence) \"Hallucination (artificial intelligence)\") |\n| Applications | * [Machine learning](/wiki/Machine_learning \"Machine learning\")   + [In-context learning](/wiki/Prompt_engineering#In-context_learning \"Prompt engineering\") * [Artificial neural network](/wiki/Neural_network_(machine_learning) \"Neural network (machine learning)\")   + [Deep learning](/wiki/Deep_learning \"Deep learning\") * [Language model](/wiki/Language_model \"Language model\")   + [Large language model](/wiki/Large_language_model \"Large language model\")   + [NMT](/wiki/Neural_machine_translation \"Neural machine translation\") * [Artificial general intelligence (AGI)](/wiki/Artificial_general_intelligence \"Artificial general intelligence\") * [Agentic AI](/wiki/Agentic_AI \"Agentic AI\") |\n| Implementations | |  |  | | --- | --- | | Audio–visual | * [AlexNet](/wiki/AlexNet \"AlexNet\") * [WaveNet](/wiki/WaveNet \"WaveNet\") * [Human image synthesis](/wiki/Human_image_synthesis \"Human image synthesis\") * [HWR](/wiki/Handwriting_recognition \"Handwriting recognition\") * [OCR](/wiki/Optical_character_recognition \"Optical character recognition\") * [Speech synthesis](/wiki/Deep_learning_speech_synthesis \"Deep learning speech synthesis\")   + [15.ai](/wiki/15.ai \"15.ai\")   + [ElevenLabs](/wiki/ElevenLabs \"ElevenLabs\") * [Speech recognition](/wiki/Speech_recognition \"Speech recognition\")   + [Whisper](/wiki/Whisper_(speech_recognition_system) \"Whisper (speech recognition system)\") * [Facial recognition](/wiki/Facial_recognition_system \"Facial recognition system\") * [AlphaFold](/wiki/AlphaFold \"AlphaFold\") * [Text-to-image models](/wiki/Text-to-image_model \"Text-to-image model\")   + [Aurora](/wiki/Aurora_(text-to-image_model) \"Aurora (text-to-image model)\")   + [DALL-E](/wiki/DALL-E \"DALL-E\")   + [Firefly](/wiki/Adobe_Firefly \"Adobe Firefly\")   + [Flux](/wiki/Flux_(text-to-image_model) \"Flux (text-to-image model)\")   + [Ideogram](/wiki/Ideogram_(text-to-image_model) \"Ideogram (text-to-image model)\")   + [Imagen](/wiki/Imagen_(text-to-image_model) \"Imagen (text-to-image model)\")   + [Midjourney](/wiki/Midjourney \"Midjourney\")   + [Stable Diffusion](/wiki/Stable_Diffusion \"Stable Diffusion\") * [Text-to-video models](/wiki/Text-to-video_model \"Text-to-video model\")   + [Dream Machine](/wiki/Dream_Machine_(text-to-video_model) \"Dream Machine (text-to-video model)\")   + [Runway Gen](/wiki/Runway_(company) \"Runway (company)\")   + [Hailuo AI](/wiki/MiniMax_(company)#Hailuo_AI \"MiniMax (company)\")   + [Kling](/wiki/Kling_(text-to-video_model) \"Kling (text-to-video model)\")   + [Sora](/wiki/Sora_(text-to-video_model) \"Sora (text-to-video model)\")   + [Veo](/wiki/Google_DeepMind#Video_generation \"Google DeepMind\") * [Music generation](/wiki/Music_and_artificial_intelligence \"Music and artificial intelligence\")   + [Suno AI](/wiki/Suno_AI \"Suno AI\")   + [Udio](/wiki/Udio \"Udio\") | | Text | * [Word2vec](/wiki/Word2vec \"Word2vec\") * [Seq2seq](/wiki/Seq2seq \"Seq2seq\") * [GloVe](/wiki/GloVe \"GloVe\") * [BERT](/wiki/BERT_(language_model) \"BERT (language model)\") * [T5](/wiki/T5_(language_model) \"T5 (language model)\") * [Llama](/wiki/Llama_(language_model) \"Llama (language model)\") * [Chinchilla AI](/wiki/Chinchilla_(language_model) \"Chinchilla (language model)\") * [PaLM](/wiki/PaLM \"PaLM\") * [GPT](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\")   + [1](/wiki/GPT-1 \"GPT-1\")   + [2](/wiki/GPT-2 \"GPT-2\")   + [3](/wiki/GPT-3 \"GPT-3\")   + [J](/wiki/GPT-J \"GPT-J\")   + [ChatGPT](/wiki/ChatGPT \"ChatGPT\")   + [4](/wiki/GPT-4 \"GPT-4\")   + [4o](/wiki/GPT-4o \"GPT-4o\")   + [o1](/wiki/OpenAI_o1 \"OpenAI o1\")   + [o3](/wiki/OpenAI_o3 \"OpenAI o3\")   + [4.5](/wiki/GPT-4.5 \"GPT-4.5\")   + [4.1](/wiki/GPT-4.1 \"GPT-4.1\")   + [o4](/wiki/OpenAI_o4-mini \"OpenAI o4-mini\") * [Claude](/wiki/Claude_(language_model) \"Claude (language model)\") * [Gemini](/wiki/Gemini_(language_model) \"Gemini (language model)\")   + [chatbot](/wiki/Gemini_(chatbot) \"Gemini (chatbot)\") * [Grok](/wiki/Grok_(chatbot) \"Grok (chatbot)\") * [LaMDA](/wiki/LaMDA \"LaMDA\") * [BLOOM](/wiki/BLOOM_(language_model) \"BLOOM (language model)\") * [Project Debater](/wiki/Project_Debater \"Project Debater\") * [IBM Watson](/wiki/IBM_Watson \"IBM Watson\") * [IBM Watsonx](/wiki/IBM_Watsonx \"IBM Watsonx\") * [Granite](/wiki/IBM_Granite \"IBM Granite\") * [PanGu-Σ](/wiki/Huawei_PanGu \"Huawei PanGu\") * [DeepSeek](/wiki/DeepSeek_(chatbot) \"DeepSeek (chatbot)\") * [Qwen](/wiki/Qwen \"Qwen\") | | Decisional | * [AlphaGo](/wiki/AlphaGo \"AlphaGo\") * [AlphaZero](/wiki/AlphaZero \"AlphaZero\") * [OpenAI Five](/wiki/OpenAI_Five \"OpenAI Five\") * [Self-driving car](/wiki/Self-driving_car \"Self-driving car\") * [MuZero](/wiki/MuZero \"MuZero\") * [Action selection](/wiki/Action_selection \"Action selection\")   + [AutoGPT](/wiki/AutoGPT \"AutoGPT\") * [Robot control](/wiki/Robot_control \"Robot control\") | |\n| People | * [Alan Turing](/wiki/Alan_Turing \"Alan Turing\") * [Warren Sturgis McCulloch](/wiki/Warren_Sturgis_McCulloch \"Warren Sturgis McCulloch\") * [Walter Pitts](/wiki/Walter_Pitts \"Walter Pitts\") * [John von Neumann](/wiki/John_von_Neumann \"John von Neumann\") * [Claude Shannon](/wiki/Claude_Shannon \"Claude Shannon\") * [Marvin Minsky](/wiki/Marvin_Minsky \"Marvin Minsky\") * [John McCarthy](/wiki/John_McCarthy_(computer_scientist) \"John McCarthy (computer scientist)\") * [Nathaniel Rochester](/wiki/Nathaniel_Rochester_(computer_scientist) \"Nathaniel Rochester (computer scientist)\") * [Allen Newell](/wiki/Allen_Newell \"Allen Newell\") * [Cliff Shaw](/wiki/Cliff_Shaw \"Cliff Shaw\") * [Herbert A. Simon](/wiki/Herbert_A._Simon \"Herbert A. Simon\") * [Oliver Selfridge](/wiki/Oliver_Selfridge \"Oliver Selfridge\") * [Frank Rosenblatt](/wiki/Frank_Rosenblatt \"Frank Rosenblatt\") * [Bernard Widrow](/wiki/Bernard_Widrow \"Bernard Widrow\") * [Joseph Weizenbaum](/wiki/Joseph_Weizenbaum \"Joseph Weizenbaum\") * [Seymour Papert](/wiki/Seymour_Papert \"Seymour Papert\") * [Seppo Linnainmaa](/wiki/Seppo_Linnainmaa \"Seppo Linnainmaa\") * [Paul Werbos](/wiki/Paul_Werbos \"Paul Werbos\") * [Jürgen Schmidhuber](/wiki/J%C3%BCrgen_Schmidhuber \"Jürgen Schmidhuber\") * [Yann LeCun](/wiki/Yann_LeCun \"Yann LeCun\") * [Geoffrey Hinton](/wiki/Geoffrey_Hinton \"Geoffrey Hinton\") * [John Hopfield](/wiki/John_Hopfield \"John Hopfield\") * [Yoshua Bengio](/wiki/Yoshua_Bengio \"Yoshua Bengio\") * [Lotfi A. Zadeh](/wiki/Lotfi_A._Zadeh \"Lotfi A. Zadeh\") * [Stephen Grossberg](/wiki/Stephen_Grossberg \"Stephen Grossberg\") * [Alex Graves](/wiki/Alex_Graves_(computer_scientist) \"Alex Graves (computer scientist)\") * [Andrew Ng](/wiki/Andrew_Ng \"Andrew Ng\") * [Fei-Fei Li](/wiki/Fei-Fei_Li \"Fei-Fei Li\") * [Alex Krizhevsky](/wiki/Alex_Krizhevsky \"Alex Krizhevsky\") * [Ilya Sutskever](/wiki/Ilya_Sutskever \"Ilya Sutskever\") * [Demis Hassabis](/wiki/Demis_Hassabis \"Demis Hassabis\") * [David Silver](/wiki/David_Silver_(computer_scientist) \"David Silver (computer scientist)\") * [Ian Goodfellow](/wiki/Ian_Goodfellow \"Ian Goodfellow\") * [Andrej Karpathy](/wiki/Andrej_Karpathy \"Andrej Karpathy\") * [James Goodnight](/wiki/James_Goodnight \"James Goodnight\") |\n| Architectures | * [Neural Turing machine](/wiki/Neural_Turing_machine \"Neural Turing machine\") * [Differentiable neural computer](/wiki/Differentiable_neural_computer \"Differentiable neural computer\") * [Transformer](/wiki/Transformer_(deep_learning_architecture) \"Transformer (deep learning architecture)\")   + [Vision transformer (ViT)](/wiki/Vision_transformer \"Vision transformer\") * [Recurrent neural network (RNN)](/wiki/Recurrent_neural_network \"Recurrent neural network\") * [Long short-term memory (LSTM)](/wiki/Long_short-term_memory \"Long short-term memory\") * [Gated recurrent unit (GRU)](/wiki/Gated_recurrent_unit \"Gated recurrent unit\") * [Echo state network](/wiki/Echo_state_network \"Echo state network\") * [Multilayer perceptron (MLP)](/wiki/Multilayer_perceptron \"Multilayer perceptron\") * [Convolutional neural network (CNN)](/wiki/Convolutional_neural_network \"Convolutional neural network\") * [Residual neural network (RNN)](/wiki/Residual_neural_network \"Residual neural network\") * [Highway network](/wiki/Highway_network \"Highway network\") * [Mamba](/wiki/Mamba_(deep_learning_architecture) \"Mamba (deep learning architecture)\") * [Autoencoder](/wiki/Autoencoder \"Autoencoder\") * [Variational autoencoder (VAE)](/wiki/Variational_autoencoder \"Variational autoencoder\") * [Generative adversarial network (GAN)](/wiki/Generative_adversarial_network \"Generative adversarial network\") * [Graph neural network (GNN)](/wiki/Graph_neural_network \"Graph neural network\") |\n| * Portals   + [Technology](/wiki/Portal:Technology \"Portal:Technology\") * [Category](/wiki/Category:Artificial_intelligence \"Category:Artificial intelligence\")   + [Artificial neural networks](/wiki/Category:Artificial_neural_networks \"Category:Artificial neural networks\")   + [Machine learning](/wiki/Category:Machine_learning \"Category:Machine learning\") * List   + [Companies](/wiki/List_of_artificial_intelligence_companies \"List of artificial intelligence companies\")   + [Projects](/wiki/List_of_artificial_intelligence_projects \"List of artificial intelligence projects\") | |\n\n![](https://en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1&usesul3=1)\n\nRetrieved from \"<https://en.wikipedia.org/w/index.php?title=Hugging_Face&oldid=1288693889>\"\n\n[Categories](/wiki/Help:Category \"Help:Category\"):\n\n* [Machine learning](/wiki/Category:Machine_learning \"Category:Machine learning\")\n* [Open-source artificial intelligence](/wiki/Category:Open-source_artificial_intelligence \"Category:Open-source artificial intelligence\")\n* [Privately held companies based in New York City](/wiki/Category:Privately_held_companies_based_in_New_York_City \"Category:Privately held companies based in New York City\")\n* [American companies established in 2016](/wiki/Category:American_companies_established_in_2016 \"Category:American companies established in 2016\")\n* [2016 establishments in New York City](/wiki/Category:2016_establishments_in_New_York_City \"Category:2016 establishments in New York City\")\n\nHidden categories:\n\n* [Articles with short description](/wiki/Category:Articles_with_short_description \"Category:Articles with short description\")\n* [Short description is different from Wikidata](/wiki/Category:Short_description_is_different_from_Wikidata \"Category:Short description is different from Wikidata\")\n* [Articles lacking reliable references from February 2024](/wiki/Category:Articles_lacking_reliable_references_from_February_2024 \"Category:Articles lacking reliable references from February 2024\")\n* [All articles lacking reliable references](/wiki/Category:All_articles_lacking_reliable_references \"Category:All articles lacking reliable references\")\n\n* This page was last edited on 4 May 2025, at 07:58 (UTC).\n* Text is available under the [Creative Commons Attribution-ShareAlike 4.0 License](/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License \"Wikipedia:Text of the Creative Commons Attribution-ShareAlike 4.0 International License\");\n  additional terms may apply. By using this site, you agree to the [Terms of Use](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use \"foundation:Special:MyLanguage/Policy:Terms of Use\") and [Privacy Policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy \"foundation:Special:MyLanguage/Policy:Privacy policy\"). Wikipedia® is a registered trademark of the [Wikimedia Foundation, Inc.](https://wikimediafoundation.org/), a non-profit organization.\n\n* [Privacy policy](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)\n* [About Wikipedia](/wiki/Wikipedia:About)\n* [Disclaimers](/wiki/Wikipedia:General_disclaimer)\n* [Contact Wikipedia](//en.wikipedia.org/wiki/Wikipedia:Contact_us)\n* [Code of Conduct](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct)\n* [Developers](https://developer.wikimedia.org)\n* [Statistics](https://stats.wikimedia.org/#/en.wikipedia.org)\n* [Cookie statement](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement)\n* [Mobile view](//en.m.wikipedia.org/w/index.php?title=Hugging_Face&mobileaction=toggle_view_mobile)\n\n* [![Wikimedia Foundation](/static/images/footer/wikimedia.svg)](https://www.wikimedia.org/)\n* [![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)](https://www.mediawiki.org/)\n\nSearch\n\nSearch\n\nToggle the table of contents\n\nHugging Face\n\n22 languages\n[Add topic](#)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build our multi-agent system"
      ],
      "metadata": {
        "id": "pM1SyPiTfGLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import (\n",
        "    CodeAgent,\n",
        "    ToolCallingAgent,\n",
        "    InferenceClientModel,\n",
        "    WebSearchTool,\n",
        "    LiteLLMModel,\n",
        ")\n",
        "\n",
        "model = InferenceClientModel(model_id=model_id)\n",
        "\n",
        "web_agent = ToolCallingAgent(\n",
        "    tools = [WebSearchTool(), visit_webpage],\n",
        "    model = model,\n",
        "    max_steps = 10,\n",
        "    name = \"web_search_agent\",\n",
        "    description= \"Runs web searches for you.\",\n",
        ")"
      ],
      "metadata": {
        "id": "MOkmWVNOe4ax",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:19.513749Z",
          "iopub.execute_input": "2025-05-17T04:42:19.514028Z",
          "iopub.status.idle": "2025-05-17T04:42:19.629973Z",
          "shell.execute_reply.started": "2025-05-17T04:42:19.514005Z",
          "shell.execute_reply": "2025-05-17T04:42:19.629027Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "manager_agent = CodeAgent(\n",
        "    tools = [],\n",
        "    model = model,\n",
        "    managed_agents = [web_agent],\n",
        "    additional_authorized_imports=['time', 'numpy', 'pandas'],   # just in case the agent needs these packages.\n",
        ")"
      ],
      "metadata": {
        "id": "dUDh54kIf-qn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:19.63101Z",
          "iopub.execute_input": "2025-05-17T04:42:19.631403Z",
          "iopub.status.idle": "2025-05-17T04:42:19.655504Z",
          "shell.execute_reply.started": "2025-05-17T04:42:19.631372Z",
          "shell.execute_reply": "2025-05-17T04:42:19.654595Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the system\n",
        "answer = manager_agent.run(\"If LLM training continues to scale up at the current rhythm until 2030, what would be the electric power in GW required to power the biggest training runs by 2030? What would that correspond to, compared to some countries> Please provide a source for any numbers used.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n17_0OC-gNgL",
        "outputId": "a4be4f57-9fe1-48b4-beb5-4c4f76c9b0a9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T04:42:19.656407Z",
          "iopub.execute_input": "2025-05-17T04:42:19.656677Z",
          "iopub.status.idle": "2025-05-17T04:42:20.132346Z",
          "shell.execute_reply.started": "2025-05-17T04:42:19.656639Z",
          "shell.execute_reply": "2025-05-17T04:42:20.130621Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mIf LLM training continues to scale up at the current rhythm until 2030, what would be the electric power in GW \u001b[0m \u001b[38;2;212;183;2m│\u001b[0m\n\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mrequired to power the biggest training runs by 2030? What would that correspond to, compared to some countries>\u001b[0m \u001b[38;2;212;183;2m│\u001b[0m\n\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mPlease provide a source for any numbers used.\u001b[0m                                                                   \u001b[38;2;212;183;2m│\u001b[0m\n\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m InferenceClientModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">If LLM training continues to scale up at the current rhythm until 2030, what would be the electric power in GW </span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">required to power the biggest training runs by 2030? What would that correspond to, compared to some countries&gt;</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Please provide a source for any numbers used.</span>                                                                   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ InferenceClientModel - Qwen/Qwen2.5-Coder-32B-Instruct ────────────────────────────────────────────────────────╯</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1;31mError in generating model output:\u001b[0m\n\u001b[1;36m401\u001b[0m\u001b[1;31m Client Error: Unauthorized for url: \u001b[0m\n\u001b[4;94mhttps://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: \u001b[0m\n\u001b[1;33mRoot\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;31m-682813ab-474d689b7d3dc8737d5ef5f7;\u001b[0m\u001b[93mf63e0eaa-0174-4ea0-b894-b4cc70c3012a\u001b[0m\u001b[1;31m)\u001b[0m\n\n\u001b[1;31mInvalid username or password.\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating model output:</span>\n<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Client Error: Unauthorized for url: </span>\n<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> (Request ID: </span>\n<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Root</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">-682813ab-474d689b7d3dc8737d5ef5f7;</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">f63e0eaa-0174-4ea0-b894-b4cc70c3012a</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span>\n\n<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Invalid username or password.</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[2m[Step 1: Duration 0.34 seconds]\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 0.34 seconds]</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smolagents/agents.py\u001b[0m in \u001b[0;36m_step_stream\u001b[0;34m(self, memory_step)\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 chat_message: ChatMessage = self.model.generate(\n\u001b[0m\u001b[1;32m   1334\u001b[0m                     \u001b[0minput_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smolagents/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop_sequences, grammar, tools_to_call_from, **kwargs)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         )\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcompletion_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mchat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[1;32m    922\u001b[0m         )\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36m_inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-682813ab-474d689b7d3dc8737d5ef5f7;f63e0eaa-0174-4ea0-b894-b4cc70c3012a)\n\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAgentGenerationError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_31/1973099771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If LLM training continues to scale up at the current rhythm until 2030, what would be the electric power in GW required to power the biggest training runs by 2030? What would that correspond to, compared to some countries> Please provide a source for any numbers used.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smolagents/agents.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, task, stream, reset, images, additional_args, max_steps)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# Outputs are returned only at the end. We only look at the last step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     def _run_stream(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smolagents/agents.py\u001b[0m in \u001b[0;36m_run_stream\u001b[0;34m(self, task, max_steps, images)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAgentGenerationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;31m# Agent generation errors are not caused by a Model error but an implementation error: so we should raise them and exit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAgentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;31m# Other AgentError types are caused by the Model, so we should log them and iterate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smolagents/agents.py\u001b[0m in \u001b[0;36m_run_stream\u001b[0;34m(self, task, max_steps, images)\u001b[0m\n\u001b[1;32m    372\u001b[0m             )\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0mfinal_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smolagents/agents.py\u001b[0m in \u001b[0;36m_execute_step\u001b[0;34m(self, memory_step)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step {self.step_number}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogLevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mfinal_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0mfinal_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smolagents/agents.py\u001b[0m in \u001b[0;36m_step_stream\u001b[0;34m(self, memory_step)\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mmemory_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAgentGenerationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error in generating model output:\\n{e}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0;31m### Parse output ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAgentGenerationError\u001b[0m: Error in generating model output:\n401 Client Error: Unauthorized for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-682813ab-474d689b7d3dc8737d5ef5f7;f63e0eaa-0174-4ea0-b894-b4cc70c3012a)\n\nInvalid username or password."
          ],
          "ename": "AgentGenerationError",
          "evalue": "Error in generating model output:\n401 Client Error: Unauthorized for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-682813ab-474d689b7d3dc8737d5ef5f7;f63e0eaa-0174-4ea0-b894-b4cc70c3012a)\n\nInvalid username or password.",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WMCnH5b5gzvS",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}